Loading vit32 model
INFO:3090:Loading vit32 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vit32', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vit32', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vit32 -- Batch: 1; Input: 224
INFO:3090:Benchmarking vit32 -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - There may be undefined behavior using dynamic shape and aten::size
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/timm/models/layers/patch_embed.py:33: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert H == self.img_size[0] and W == self.img_size[1], \
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/timm/models/vision_transformer.py:186: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 58, in _optimize_model
    trt_model = torch_tensorrt.compile(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch_tensorrt/_compile.py", line 125, in compile
    return torch_tensorrt.ts.compile(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch_tensorrt/ts/_compiler.py", line 136, in compile
    compiled_cpp_mod = _C.compile_graph(module._c, _parse_compile_spec(spec))
RuntimeError: [Error thrown at core/conversion/converters/converter_util.cpp:202] Unable to freeze tensor of type Int64/Float64 into constant layer, try to compile model with truncate_long_and_double enabled

Loading efficientnet model
INFO:3090:Loading efficientnet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 1; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 2; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 4; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 8; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 16; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 32; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 64; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 96; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 128; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 192; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 256; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 384; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 512; Input: 224
INFO:3090:Benchmarking efficientnet -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Loading efficientnet_lite model
INFO:3090:Loading efficientnet_lite model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 1; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 2; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 4; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 8; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 16; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 32; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 64; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 96; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 128; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 192; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 256; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 384; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 512; Input: 224
INFO:3090:Benchmarking efficientnet_lite -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Loading gernet model
INFO:3090:Loading gernet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 1; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 2; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 4; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 8; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 16; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 32; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 64; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 96; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 128; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 192; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 256; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 384; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 512; Input: 224
INFO:3090:Benchmarking gernet -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Loading resnet18 model
INFO:3090:Loading resnet18 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 1; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 2; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 4; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 8; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 16; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 32; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 64; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 96; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 128; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 192; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 256; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 384; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 512; Input: 224
INFO:3090:Benchmarking resnet18 -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Loading alexnet model
INFO:3090:Loading alexnet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 1; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 2; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 4; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 8; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 16; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 32; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 64; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 96; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 128; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 192; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 256; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 384; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 512; Input: 224
INFO:3090:Benchmarking alexnet -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Loading squeezenet model
INFO:3090:Loading squeezenet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 1; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 2; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 4; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 8; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 16; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 32; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 64; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 96; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 128; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 192; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 256; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 384; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 512; Input: 224
INFO:3090:Benchmarking squeezenet -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Loading vgg16 model
INFO:3090:Loading vgg16 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 1; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 2; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 4; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 8; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 16; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 32; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 64; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 96; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 128; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 192; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 256; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000001.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000039.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 384; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000001.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000038.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000039.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000070.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000071.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000076.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x01cf8ce2da913006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x12dbf7d94ee3696d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3f243c490d502deb.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x4727434768e46395.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x4efce38acc876f5c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x503619c69ae500ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5403ad713f811a18.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5aa723e0481da855.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5deb29b7a8e275f7.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 17179869184 detected for tactic 0x94119b4c514b211a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0xa31d27de74b895ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0xa38325fb84d2eb60.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 17179869184 detected for tactic 0xa8609adc4e0ceb90.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0xb1e4019cd8c44d5e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0xbb8c3889c7eacd30.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 17179869184 detected for tactic 0xd828f024626fa982.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf067e6205da31c2e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf64396b97c889179.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x19b688348f983aa0.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x1da91d865428f237.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x27b316f52c109002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3e191488237fab8f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3e2b881168d9689d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3f0c846d6379bc98.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x412c44dfeaf9161d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5030121339a48bf3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x62835fce994f06dd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 17179869184 detected for tactic 0x634e99502974e4da.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0x65e41d81f093b482.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x7bc32c782b800c48.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 17179869184 detected for tactic 0x8014228ec08b4d49.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x94a7db94ba744c45.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x999e005e3b016ea6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 17179869184 detected for tactic 0xb443c221fcb1565b.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 17179869184 detected for tactic 0xbdfdef6b84f7ccc9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 17179869184 detected for tactic 0xca7eeb8d9143d738.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 18 due to insufficient memory on requested size of 17179869184 detected for tactic 0xd15dd11d64344e83.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 19 due to insufficient memory on requested size of 17179869184 detected for tactic 0xd9031472c05adf51.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 20 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf48db81f02eca9ee.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 21 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf90060ce8193b811.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x65e41d81f093b482.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x999e005e3b016ea6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0xb443c221fcb1565b.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 512; Input: 224
INFO:3090:Benchmarking vgg16 -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Adaptive pooling layer will be using Aten library kernels in pytorch for execution. TensorRT does not support adaptive pooling natively. Consider switching to non-adaptive pooling if this is an issue
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003e8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x00000000000003ea.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000001.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000038.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000039.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000070.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000071.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000076.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x01cf8ce2da913006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x12dbf7d94ee3696d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3f243c490d502deb.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4727434768e46395.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4efce38acc876f5c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 8589934592 detected for tactic 0x503619c69ae500ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5403ad713f811a18.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5aa723e0481da855.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5deb29b7a8e275f7.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0x94119b4c514b211a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa31d27de74b895ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa38325fb84d2eb60.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa8609adc4e0ceb90.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb1e4019cd8c44d5e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbb8c3889c7eacd30.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd828f024626fa982.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf067e6205da31c2e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf64396b97c889179.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x19b688348f983aa0.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x1da91d865428f237.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3f0c846d6379bc98.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5030121339a48bf3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x62835fce994f06dd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 8589934592 detected for tactic 0x8014228ec08b4d49.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0x94a7db94ba744c45.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0xca7eeb8d9143d738.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd15dd11d64344e83.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd9031472c05adf51.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf48db81f02eca9ee.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x19b688348f983aa0.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x1da91d865428f237.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x27b316f52c109002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3e191488237fab8f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3e2b881168d9689d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3f0c846d6379bc98.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0x412c44dfeaf9161d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5030121339a48bf3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x62835fce994f06dd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0x634e99502974e4da.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 8589934592 detected for tactic 0x65e41d81f093b482.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 8589934592 detected for tactic 0x7bc32c782b800c48.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 8589934592 detected for tactic 0x8014228ec08b4d49.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x94a7db94ba744c45.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 8589934592 detected for tactic 0x999e005e3b016ea6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb443c221fcb1565b.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbdfdef6b84f7ccc9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 8589934592 detected for tactic 0xca7eeb8d9143d738.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 18 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd15dd11d64344e83.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 19 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd9031472c05adf51.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 20 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf48db81f02eca9ee.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 21 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf90060ce8193b811.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000001.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000038.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000039.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000070.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000071.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000076.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x01cf8ce2da913006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x12dbf7d94ee3696d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3f243c490d502deb.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x4727434768e46395.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x4efce38acc876f5c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x503619c69ae500ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5403ad713f811a18.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5aa723e0481da855.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5deb29b7a8e275f7.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 17179869184 detected for tactic 0x94119b4c514b211a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0xa31d27de74b895ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0xa38325fb84d2eb60.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 17179869184 detected for tactic 0xa8609adc4e0ceb90.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0xb1e4019cd8c44d5e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0xbb8c3889c7eacd30.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 17179869184 detected for tactic 0xd828f024626fa982.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf067e6205da31c2e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf64396b97c889179.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x19b688348f983aa0.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x1da91d865428f237.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x27b316f52c109002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3e191488237fab8f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3e2b881168d9689d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 17179869184 detected for tactic 0x3f0c846d6379bc98.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x412c44dfeaf9161d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x5030121339a48bf3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x62835fce994f06dd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 17179869184 detected for tactic 0x634e99502974e4da.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0x65e41d81f093b482.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x7bc32c782b800c48.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 17179869184 detected for tactic 0x8014228ec08b4d49.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x94a7db94ba744c45.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x999e005e3b016ea6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 17179869184 detected for tactic 0xb443c221fcb1565b.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 17179869184 detected for tactic 0xbdfdef6b84f7ccc9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 17179869184 detected for tactic 0xca7eeb8d9143d738.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 18 due to insufficient memory on requested size of 17179869184 detected for tactic 0xd15dd11d64344e83.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 19 due to insufficient memory on requested size of 17179869184 detected for tactic 0xd9031472c05adf51.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 20 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf48db81f02eca9ee.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 21 due to insufficient memory on requested size of 17179869184 detected for tactic 0xf90060ce8193b811.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 17179869184 detected for tactic 0x65e41d81f093b482.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 17179869184 detected for tactic 0x999e005e3b016ea6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0xb443c221fcb1565b.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000000.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000001.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 34359738368 detected for tactic 0x0000000000000006.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000038.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (34359738368 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 34359738368 detected for tactic 0x000000000000003e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x1e7896ba71ef1635.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x2f735ffbb05a30fd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x360278e347d63410.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4cfee77ea8c324db.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x540fde3a7bee53dc.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 8589934592 detected for tactic 0x91f7e9c0851ad67c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb837f96ef306f686.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc34b78af38b295a7.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc754debea88ae0b7.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0xea8b68014eaeb55d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x03896956a39a1203.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x048d6d0400f33439.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x05b6220f243edacd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0866ddee325d07a6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0e07ff4f4f7c1ac9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 8589934592 detected for tactic 0x100c1ad308e08d35.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0x17ebf0c9f418f10a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x196cbc423a9bb69e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x19822de884f42a6a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0x1a5ba808ad4cc5a8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 8589934592 detected for tactic 0x21b295c0c8f6c95a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 8589934592 detected for tactic 0x234580e8a194335c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 8589934592 detected for tactic 0x245530c34bd6090f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x24e01e7405cfdfe9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 8589934592 detected for tactic 0x263a38afd75e3a43.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 8589934592 detected for tactic 0x2721a7f18c2700db.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 8589934592 detected for tactic 0x29329b5741ea05f2.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 8589934592 detected for tactic 0x2970ae65966d569d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 18 due to insufficient memory on requested size of 8589934592 detected for tactic 0x2eaa2202de9404d6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 19 due to insufficient memory on requested size of 8589934592 detected for tactic 0x30c0f36d0aeeac6a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 20 due to insufficient memory on requested size of 8589934592 detected for tactic 0x30e8a8d7a953e5e9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 21 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3197d5044d71e98e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 22 due to insufficient memory on requested size of 8589934592 detected for tactic 0x31d93dc22d2af081.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 23 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3369260c04f9ad73.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 24 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3b5fa0f2a8fc2410.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 25 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3e7eb35b91b9fa63.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 26 due to insufficient memory on requested size of 8589934592 detected for tactic 0x42a5b8709d0039be.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 27 due to insufficient memory on requested size of 8589934592 detected for tactic 0x463794ee4acffd1f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 28 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4a81ea1e51436a30.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 29 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4aed1956bd10a795.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 30 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4fc05923455fc266.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 31 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5013c38f55afa9ba.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 32 due to insufficient memory on requested size of 8589934592 detected for tactic 0x529f4431bdae94f5.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 33 due to insufficient memory on requested size of 8589934592 detected for tactic 0x53be5e206184e6ad.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 34 due to insufficient memory on requested size of 8589934592 detected for tactic 0x544bff7ff9c5d908.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 35 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5568fd8a32f4a40f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 36 due to insufficient memory on requested size of 8589934592 detected for tactic 0x57c9a5ff682354a6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 37 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5820b3dda403c4d0.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 38 due to insufficient memory on requested size of 8589934592 detected for tactic 0x58816bf2e9c36afb.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 39 due to insufficient memory on requested size of 8589934592 detected for tactic 0x59762bd684092b33.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 40 due to insufficient memory on requested size of 8589934592 detected for tactic 0x59c5c647b4c76593.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 41 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5c2e1c87d85b06f1.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 42 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5f31c22ec167f384.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 43 due to insufficient memory on requested size of 8589934592 detected for tactic 0x60c3421152ef8e10.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 44 due to insufficient memory on requested size of 8589934592 detected for tactic 0x60da8c7151d91e47.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 45 due to insufficient memory on requested size of 8589934592 detected for tactic 0x6426696f872a3b13.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 46 due to insufficient memory on requested size of 8589934592 detected for tactic 0x699be152cfb6d6ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 47 due to insufficient memory on requested size of 8589934592 detected for tactic 0x6af049035146c349.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 48 due to insufficient memory on requested size of 8589934592 detected for tactic 0x7005d10718f6c22d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 49 due to insufficient memory on requested size of 8589934592 detected for tactic 0x706f08da35c795a5.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 50 due to insufficient memory on requested size of 8589934592 detected for tactic 0x7163d33a4d8ce8d7.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 51 due to insufficient memory on requested size of 8589934592 detected for tactic 0x7aad3976677d7155.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 52 due to insufficient memory on requested size of 8589934592 detected for tactic 0x8015519605ab9963.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 53 due to insufficient memory on requested size of 8589934592 detected for tactic 0x82f8a2214b0b4178.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 54 due to insufficient memory on requested size of 8589934592 detected for tactic 0x834e11ecd4ab9454.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 55 due to insufficient memory on requested size of 8589934592 detected for tactic 0x83ccd4762c1376a1.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 56 due to insufficient memory on requested size of 8589934592 detected for tactic 0x866e7a5f6401b67f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 57 due to insufficient memory on requested size of 8589934592 detected for tactic 0x88971eec55aba850.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 58 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa033e20ae9f412b2.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 59 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa111596c001b78db.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 60 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa1a20ea714d420f4.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 61 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa40cb43c296a36a8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 62 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa570c55d303796ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 63 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa7c9d418a10bce71.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 64 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa83b68f30462f971.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 65 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa9177bbe4e767df8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 66 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa927df92ac1ef1b8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 67 due to insufficient memory on requested size of 8589934592 detected for tactic 0xabd92c9ae596b545.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 68 due to insufficient memory on requested size of 8589934592 detected for tactic 0xafd1e8bf6bd3d638.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 69 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb17d53d15dfbfc9e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 70 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb33e57fb3e8a0a56.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 71 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb4bec086187edcfc.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 72 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb85e52e87caf60a2.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 73 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb8d86216e1235cda.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 74 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbd08239a9317f2fd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 75 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbd6f5e6f24c05c10.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 76 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbeaee7eaad288322.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 77 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc0a02dc6095497cc.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 78 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc2cf926c41243630.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 79 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc338d2482cee77f8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 80 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc660e51970bc5a3a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 81 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc82f3f06140e3cbb.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 82 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc8a90ff8898200c3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 83 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc9cc55109bb4de26.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 84 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc9d24bd069159fa8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 85 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc9f0a7bec963ba66.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 86 due to insufficient memory on requested size of 8589934592 detected for tactic 0xca5d3a11fd48f571.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 87 due to insufficient memory on requested size of 8589934592 detected for tactic 0xce0506e1512285c3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 88 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd0a3e0c815f7fb5e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 89 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd1aaad17ca35fbaa.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 90 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd58ea0bdedb89ead.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 91 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd8eb41ee35e76575.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 92 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdb0b80f591d1bb6d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 93 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdc796d70e228a1d4.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 94 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdce100b9fe609424.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 95 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdfa020ef435ef810.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 96 due to insufficient memory on requested size of 8589934592 detected for tactic 0xe0e3c0e8cf9a2d9e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 97 due to insufficient memory on requested size of 8589934592 detected for tactic 0xe1ff5ad20f5c6bf6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 98 due to insufficient memory on requested size of 8589934592 detected for tactic 0xe4711898bd599c36.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 99 due to insufficient memory on requested size of 8589934592 detected for tactic 0xeb2d2aa4e56bb41c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 100 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf0beb09df9a19f82.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 101 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf35e0311fa1cc516.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 102 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf79479a62ea9f901.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 0 due to insufficient memory on requested size of 8589934592 detected for tactic 0x03896956a39a1203.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 1 due to insufficient memory on requested size of 8589934592 detected for tactic 0x048d6d0400f33439.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 8589934592 detected for tactic 0x05b6220f243edacd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0866ddee325d07a6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0e07ff4f4f7c1ac9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 5 due to insufficient memory on requested size of 8589934592 detected for tactic 0x100c1ad308e08d35.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 8589934592 detected for tactic 0x17ebf0c9f418f10a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x196cbc423a9bb69e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x19822de884f42a6a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0x1a5ba808ad4cc5a8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 8589934592 detected for tactic 0x21b295c0c8f6c95a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 8589934592 detected for tactic 0x234580e8a194335c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 12 due to insufficient memory on requested size of 8589934592 detected for tactic 0x245530c34bd6090f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x24e01e7405cfdfe9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 8589934592 detected for tactic 0x263a38afd75e3a43.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 15 due to insufficient memory on requested size of 8589934592 detected for tactic 0x2721a7f18c2700db.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 8589934592 detected for tactic 0x29329b5741ea05f2.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 17 due to insufficient memory on requested size of 8589934592 detected for tactic 0x2970ae65966d569d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 18 due to insufficient memory on requested size of 8589934592 detected for tactic 0x2eaa2202de9404d6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 19 due to insufficient memory on requested size of 8589934592 detected for tactic 0x30c0f36d0aeeac6a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 20 due to insufficient memory on requested size of 8589934592 detected for tactic 0x30e8a8d7a953e5e9.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 21 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3197d5044d71e98e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 22 due to insufficient memory on requested size of 8589934592 detected for tactic 0x31d93dc22d2af081.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 23 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3369260c04f9ad73.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 24 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3b5fa0f2a8fc2410.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 25 due to insufficient memory on requested size of 8589934592 detected for tactic 0x3e7eb35b91b9fa63.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 26 due to insufficient memory on requested size of 8589934592 detected for tactic 0x42a5b8709d0039be.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 27 due to insufficient memory on requested size of 8589934592 detected for tactic 0x463794ee4acffd1f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 28 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4a81ea1e51436a30.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 29 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4aed1956bd10a795.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 30 due to insufficient memory on requested size of 8589934592 detected for tactic 0x4fc05923455fc266.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 31 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5013c38f55afa9ba.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 32 due to insufficient memory on requested size of 8589934592 detected for tactic 0x529f4431bdae94f5.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 33 due to insufficient memory on requested size of 8589934592 detected for tactic 0x53be5e206184e6ad.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 34 due to insufficient memory on requested size of 8589934592 detected for tactic 0x544bff7ff9c5d908.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 35 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5568fd8a32f4a40f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 36 due to insufficient memory on requested size of 8589934592 detected for tactic 0x57c9a5ff682354a6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 37 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5820b3dda403c4d0.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 38 due to insufficient memory on requested size of 8589934592 detected for tactic 0x58816bf2e9c36afb.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 39 due to insufficient memory on requested size of 8589934592 detected for tactic 0x59762bd684092b33.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 40 due to insufficient memory on requested size of 8589934592 detected for tactic 0x59c5c647b4c76593.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 41 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5c2e1c87d85b06f1.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 42 due to insufficient memory on requested size of 8589934592 detected for tactic 0x5f31c22ec167f384.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 43 due to insufficient memory on requested size of 8589934592 detected for tactic 0x60c3421152ef8e10.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 44 due to insufficient memory on requested size of 8589934592 detected for tactic 0x60da8c7151d91e47.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 45 due to insufficient memory on requested size of 8589934592 detected for tactic 0x6426696f872a3b13.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 46 due to insufficient memory on requested size of 8589934592 detected for tactic 0x699be152cfb6d6ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 47 due to insufficient memory on requested size of 8589934592 detected for tactic 0x6af049035146c349.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 48 due to insufficient memory on requested size of 8589934592 detected for tactic 0x7005d10718f6c22d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 49 due to insufficient memory on requested size of 8589934592 detected for tactic 0x706f08da35c795a5.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 50 due to insufficient memory on requested size of 8589934592 detected for tactic 0x7163d33a4d8ce8d7.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 51 due to insufficient memory on requested size of 8589934592 detected for tactic 0x7aad3976677d7155.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 52 due to insufficient memory on requested size of 8589934592 detected for tactic 0x8015519605ab9963.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 53 due to insufficient memory on requested size of 8589934592 detected for tactic 0x82f8a2214b0b4178.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 54 due to insufficient memory on requested size of 8589934592 detected for tactic 0x834e11ecd4ab9454.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 55 due to insufficient memory on requested size of 8589934592 detected for tactic 0x83ccd4762c1376a1.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 56 due to insufficient memory on requested size of 8589934592 detected for tactic 0x866e7a5f6401b67f.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 57 due to insufficient memory on requested size of 8589934592 detected for tactic 0x88971eec55aba850.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 58 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa033e20ae9f412b2.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 59 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa111596c001b78db.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 60 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa1a20ea714d420f4.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 61 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa40cb43c296a36a8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 62 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa570c55d303796ff.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 63 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa7c9d418a10bce71.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 64 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa83b68f30462f971.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 65 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa9177bbe4e767df8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 66 due to insufficient memory on requested size of 8589934592 detected for tactic 0xa927df92ac1ef1b8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 67 due to insufficient memory on requested size of 8589934592 detected for tactic 0xabd92c9ae596b545.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 68 due to insufficient memory on requested size of 8589934592 detected for tactic 0xafd1e8bf6bd3d638.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 69 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb17d53d15dfbfc9e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 70 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb33e57fb3e8a0a56.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 71 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb4bec086187edcfc.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 72 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb85e52e87caf60a2.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 73 due to insufficient memory on requested size of 8589934592 detected for tactic 0xb8d86216e1235cda.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 74 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbd08239a9317f2fd.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 75 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbd6f5e6f24c05c10.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 76 due to insufficient memory on requested size of 8589934592 detected for tactic 0xbeaee7eaad288322.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 77 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc0a02dc6095497cc.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 78 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc2cf926c41243630.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 79 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc338d2482cee77f8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 80 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc660e51970bc5a3a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 81 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc82f3f06140e3cbb.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 82 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc8a90ff8898200c3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 83 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc9cc55109bb4de26.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 84 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc9d24bd069159fa8.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 85 due to insufficient memory on requested size of 8589934592 detected for tactic 0xc9f0a7bec963ba66.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 86 due to insufficient memory on requested size of 8589934592 detected for tactic 0xca5d3a11fd48f571.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 87 due to insufficient memory on requested size of 8589934592 detected for tactic 0xce0506e1512285c3.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 88 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd0a3e0c815f7fb5e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 89 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd1aaad17ca35fbaa.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 90 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd58ea0bdedb89ead.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 91 due to insufficient memory on requested size of 8589934592 detected for tactic 0xd8eb41ee35e76575.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 92 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdb0b80f591d1bb6d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 93 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdc796d70e228a1d4.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 94 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdce100b9fe609424.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 95 due to insufficient memory on requested size of 8589934592 detected for tactic 0xdfa020ef435ef810.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 96 due to insufficient memory on requested size of 8589934592 detected for tactic 0xe0e3c0e8cf9a2d9e.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 97 due to insufficient memory on requested size of 8589934592 detected for tactic 0xe1ff5ad20f5c6bf6.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 98 due to insufficient memory on requested size of 8589934592 detected for tactic 0xe4711898bd599c36.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 99 due to insufficient memory on requested size of 8589934592 detected for tactic 0xeb2d2aa4e56bb41c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 100 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf0beb09df9a19f82.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 101 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf35e0311fa1cc516.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 102 due to insufficient memory on requested size of 8589934592 detected for tactic 0xf79479a62ea9f901.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 10: [optimizer.cpp::computeCosts::3626] Error Code 10: Internal Error (Could not find any implementation for node %input.5 : Tensor = aten::_convolution(%157, %self.features.2.weight.1, %self.features.0.bias.1, %7, %7, %7, %9, %6, %10, %9, %9, %8, %8), scope: __module.features/__module.features.2 # /home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/nn/modules/conv.py:453:0 + %159 : Tensor = aten::relu(%input.5), scope: __module.features/__module.features.3 # /home/
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [builder.cpp::buildSerializedNetwork::636] Error Code 2: Internal Error (Assertion engine != nullptr failed. )
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 58, in _optimize_model
    trt_model = torch_tensorrt.compile(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch_tensorrt/_compile.py", line 125, in compile
    return torch_tensorrt.ts.compile(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch_tensorrt/ts/_compiler.py", line 136, in compile
    compiled_cpp_mod = _C.compile_graph(module._c, _parse_compile_spec(spec))
RuntimeError: [Error thrown at core/conversion/conversionctx/ConversionCtx.cpp:169] Building serialized network failed in TensorRT

Loading densenet model
INFO:3090:Loading densenet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 1; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 2; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 4; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 8; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 16; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 32; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 64; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 96; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 128; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 192; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 256; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 384; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 512; Input: 224
INFO:3090:Benchmarking densenet -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Loading inception model
INFO:3090:Loading inception model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 1; Input: 224
INFO:3090:Benchmarking inception -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 2; Input: 224
INFO:3090:Benchmarking inception -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 4; Input: 224
INFO:3090:Benchmarking inception -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 8; Input: 224
INFO:3090:Benchmarking inception -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 16; Input: 224
INFO:3090:Benchmarking inception -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 32; Input: 224
INFO:3090:Benchmarking inception -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 64; Input: 224
INFO:3090:Benchmarking inception -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 96; Input: 224
INFO:3090:Benchmarking inception -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 128; Input: 224
INFO:3090:Benchmarking inception -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 192; Input: 224
INFO:3090:Benchmarking inception -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 256; Input: 224
INFO:3090:Benchmarking inception -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 384; Input: 224
INFO:3090:Benchmarking inception -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='inception', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking inception -- Batch: 512; Input: 224
INFO:3090:Benchmarking inception -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Loading googlenet model
INFO:3090:Loading googlenet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 1; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 2; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 4; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 8; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 16; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 32; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 64; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 96; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 128; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 192; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 256; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 384; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='googlenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking googlenet -- Batch: 512; Input: 224
INFO:3090:Benchmarking googlenet -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Loading shufflenet model
INFO:3090:Loading shufflenet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking shufflenet -- Batch: 1; Input: 224
INFO:3090:Benchmarking shufflenet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/shufflenetv2.py:30: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  channels_per_group = num_channels // groups
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 164, in aggregate_metrics
    data["latency"] = self.get_wallclock(iters)
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 75, in get_wallclock
    out = self.model(self.input_constructor())
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: [Error thrown at core/runtime/execute_engine.cpp:89] Expected inputs[pyt_idx].dtype() == expected_type to be true but got false
Expected input tensors to have type Half, found type float


Loading mobilenet_v2 model
INFO:3090:Loading mobilenet_v2 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 1; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 2; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 4; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 8; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 16; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 32; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 64; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 96; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 128; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 192; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 256; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 384; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobilenet_v2 -- Batch: 512; Input: 224
INFO:3090:Benchmarking mobilenet_v2 -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Loading resnext50_32x4d model
INFO:3090:Loading resnext50_32x4d model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 1; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 2; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 4; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 8; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 16; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 32; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 64; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 96; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 128; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 192; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 256; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 384; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnext50_32x4d -- Batch: 512; Input: 224
INFO:3090:Benchmarking resnext50_32x4d -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Loading wide_resnet50_2 model
INFO:3090:Loading wide_resnet50_2 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 1; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 2; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 4; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 8; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 16; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 32; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 64; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 96; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 128; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 192; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 256; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 384; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking wide_resnet50_2 -- Batch: 512; Input: 224
INFO:3090:Benchmarking wide_resnet50_2 -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 2 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000002.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003a.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000072.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 14 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 11 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 6 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 10 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 16 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000075.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 4 due to insufficient memory on requested size of 17179869184 detected for tactic 0x0000000000000005.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (17179869184 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 9 due to insufficient memory on requested size of 17179869184 detected for tactic 0x000000000000003d.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 8 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 13 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000074.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 3 due to insufficient memory on requested size of 8589934592 detected for tactic 0x0000000000000004.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [virtualMemoryBuffer.cpp::resizePhysical::144] Error Code 2: OutOfMemory (no further information)
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Requested amount of GPU memory (8589934592 bytes) could not be allocated. There may not be enough free memory for allocation to succeed.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - Skipping tactic 7 due to insufficient memory on requested size of 8589934592 detected for tactic 0x000000000000003c.
Try decreasing the workspace size with IBuilderConfig::setMemoryPoolLimit().
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Loading mnasnet model
INFO:3090:Loading mnasnet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 1; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 1; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 2; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 2; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 4; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 4; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 8; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 8; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 16; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 16; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 32; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 32; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 64; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 64; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 96; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 96; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 128; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 128; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 192; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 192; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 256; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 256; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 384; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 384; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mnasnet -- Batch: 512; Input: 224
INFO:3090:Benchmarking mnasnet -- Batch: 512; Input: 224
WARNING: [Torch-TensorRT] - Mean converter disregards dtype
WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
WARNING: [Torch-TensorRT TorchScript Conversion Context] - The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
Loading bert model
INFO:3090:Loading bert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking bert -- Batch: 1; Input: 128
INFO:3090:Benchmarking bert -- Batch: 1; Input: 128
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/modeling_utils.py:2154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert all(
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 57, in _optimize_model
    jit_model = torch.jit.trace(self.model, (input_example,))
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 750, in trace
    return trace_module(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 967, in trace_module
    module._c._create_method_from_trace(
RuntimeError: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
Loading distilbert model
INFO:3090:Loading distilbert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking distilbert -- Batch: 1; Input: 128
INFO:3090:Benchmarking distilbert -- Batch: 1; Input: 128
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']
- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/modeling_utils.py:2154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert all(
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 57, in _optimize_model
    jit_model = torch.jit.trace(self.model, (input_example,))
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 750, in trace
    return trace_module(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 967, in trace_module
    module._c._create_method_from_trace(
RuntimeError: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
Loading funnel_transformer model
INFO:3090:Loading funnel_transformer model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking funnel_transformer -- Batch: 1; Input: 128
INFO:3090:Benchmarking funnel_transformer -- Batch: 1; Input: 128
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/funnel/modeling_funnel.py:314: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  num_remove = shift * len(pooled_pos)
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/funnel/modeling_funnel.py:638: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  pooling_flag = pooling_flag and block_index > 0
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/funnel/modeling_funnel.py:481: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  shift = 2 if q_head.shape[1] != context_len else 1
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 57, in _optimize_model
    jit_model = torch.jit.trace(self.model, (input_example,))
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 750, in trace
    return trace_module(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 967, in trace_module
    module._c._create_method_from_trace(
RuntimeError: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
Loading albert model
INFO:3090:Loading albert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking albert -- Batch: 1; Input: 128
INFO:3090:Benchmarking albert -- Batch: 1; Input: 128
Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias']
- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/modeling_utils.py:2154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert all(
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 57, in _optimize_model
    jit_model = torch.jit.trace(self.model, (input_example,))
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 750, in trace
    return trace_module(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 967, in trace_module
    module._c._create_method_from_trace(
RuntimeError: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
Loading longformer model
INFO:3090:Loading longformer model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking longformer -- Batch: 1; Input: 128
INFO:3090:Benchmarking longformer -- Batch: 1; Input: 128
Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:1544: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if padding_len > 0:
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:1247: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  is_global_attn = is_index_global_attn.flatten().any().item()
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:580: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert (
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:801: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert (
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:804: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert query.size() == key.size()
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:806: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  chunks_count = seq_len // window_overlap - 1
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:769: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  hidden_states.size(1) // (window_overlap * 2),
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:609: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert list(attn_scores.size()) == [
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:869: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert seq_len % (window_overlap * 2) == 0
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:870: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert attn_probs.size()[:3] == value.size()[:3]
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:871: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert attn_probs.size(3) == 2 * window_overlap + 1
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:872: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  chunks_count = seq_len // window_overlap - 1
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:876: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  batch_size * num_heads, seq_len // window_overlap, window_overlap, 2 * window_overlap + 1
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:680: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert attn_output.size() == (batch_size, seq_len, self.num_heads, self.head_dim), "Unexpected size"
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/modeling_utils.py:2154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert all(
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/longformer/modeling_longformer.py:1681: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if padding_len > 0:
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 57, in _optimize_model
    jit_model = torch.jit.trace(self.model, (input_example,))
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 750, in trace
    return trace_module(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 967, in trace_module
    module._c._create_method_from_trace(
RuntimeError: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
Loading mobile_bert model
INFO:3090:Loading mobile_bert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking mobile_bert -- Batch: 1; Input: 128
INFO:3090:Benchmarking mobile_bert -- Batch: 1; Input: 128
Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing MobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing MobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:522: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  torch.tensor(1000),
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 57, in _optimize_model
    jit_model = torch.jit.trace(self.model, (input_example,))
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 750, in trace
    return trace_module(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 967, in trace_module
    module._c._create_method_from_trace(
RuntimeError: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
Loading squeeze_bert model
INFO:3090:Loading squeeze_bert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
INFO:3090:Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='3090', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeeze_bert -- Batch: 1; Input: 128
INFO:3090:Benchmarking squeeze_bert -- Batch: 1; Input: 128
Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Traceback (most recent call last):
  File "pytorch/main_pretrained.py", line 147, in <module>
    main(args)
  File "pytorch/main_pretrained.py", line 101, in main
    data = benchmarker.aggregate_metrics()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 163, in aggregate_metrics
    self._optimize_model()
  File "/home/jaredfer/Projects/DeviceBenchmarking/pytorch/benchmark.py", line 57, in _optimize_model
    jit_model = torch.jit.trace(self.model, (input_example,))
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 750, in trace
    return trace_module(
  File "/home/jaredfer/anaconda3/envs/device_benchmarking/lib/python3.8/site-packages/torch/jit/_trace.py", line 967, in trace_module
    module._c._create_method_from_trace(
RuntimeError: Encountering a dict at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
