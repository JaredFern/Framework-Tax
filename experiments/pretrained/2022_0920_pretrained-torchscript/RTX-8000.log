Loading shufflenet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='shufflenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking shufflenet -- Batch: 512; Input: 224
Loading mobilenet_v2 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mobilenet_v2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobilenet_v2 -- Batch: 512; Input: 224
Loading resnext50_32x4d model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='resnext50_32x4d', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking resnext50_32x4d -- Batch: 512; Input: 224
Loading wide_resnet50_2 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='wide_resnet50_2', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking wide_resnet50_2 -- Batch: 512; Input: 224
Loading mnasnet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[224], iters=10, model='mnasnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mnasnet -- Batch: 512; Input: 224
Loading bert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 1; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 2; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 4; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 8; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 16; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 32; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 64; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 96; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 128; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 192; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 256; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 384; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking bert -- Batch: 512; Input: 128
Loading distilbert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 1; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 2; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 4; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 8; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 16; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 32; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 64; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 96; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 128; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 192; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 256; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 384; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='distilbert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking distilbert -- Batch: 512; Input: 128
Loading funnel_transformer model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 1; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 2; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 4; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 8; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 16; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 32; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 64; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 96; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 128; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 192; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 256; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 384; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='funnel_transformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking funnel_transformer -- Batch: 512; Input: 128
Loading albert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 1; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 2; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 4; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 8; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 16; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 32; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 64; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 96; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 128; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 192; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 256; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 384; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='albert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking albert -- Batch: 512; Input: 128
Loading longformer model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 1; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 2; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 4; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 8; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 16; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 32; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 64; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 96; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 128; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 192; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 256; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 384; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='longformer', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking longformer -- Batch: 512; Input: 128
Loading mobile_bert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 1; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 2; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 4; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 8; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 16; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 32; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 64; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 96; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 128; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 192; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 256; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 384; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='mobile_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking mobile_bert -- Batch: 512; Input: 128
Loading squeeze_bert model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 1; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 2; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 4; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 8; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 16; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 32; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 64; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 96; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 128; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 192; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 256; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 384; Input: 128
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-torchscript', input_size=[128], iters=10, model='squeeze_bert', model_config='pytorch/config/models/transformers.yaml', num_threads=1, platform='RTX-8000', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=False, use_ipex=False, use_jit=True, use_tensorrt=False)
Benchmarking squeeze_bert -- Batch: 512; Input: 128
