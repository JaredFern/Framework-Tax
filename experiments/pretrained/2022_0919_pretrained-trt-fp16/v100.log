Loading vit32 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vit32', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vit32 -- Batch: 1; Input: 224
Loading efficientnet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet -- Batch: 512; Input: 224
Loading efficientnet_lite model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='efficientnet_lite', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking efficientnet_lite -- Batch: 512; Input: 224
Loading gernet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='gernet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking gernet -- Batch: 512; Input: 224
Loading resnet18 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='resnet18', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking resnet18 -- Batch: 512; Input: 224
Loading alexnet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='alexnet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking alexnet -- Batch: 512; Input: 224
Loading squeezenet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='squeezenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking squeezenet -- Batch: 512; Input: 224
Loading vgg16 model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='vgg16', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking vgg16 -- Batch: 512; Input: 224
Loading densenet model
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 1; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 2; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 4; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 8; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 16; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 32; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 64; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 96; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 128; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 192; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 256; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 384; Input: 224
Run Parameters: Namespace(act_fn='relu', batch_size=[1, 2, 4, 8, 16, 32, 64, 96, 128, 192, 256, 384, 512], device='cuda', device_config='pytorch/config/devices/cuda.yaml', device_idx=0, dropout=None, exp_name='pretrained-trt-fp16', input_size=[224], iters=10, model='densenet', model_config='pytorch/config/models/vision.yaml', num_threads=1, platform='v100', randomized_text=True, requires_grad=False, results_dir='pytorch/experiments/pretrained', use_channels_last=False, use_cuda=True, use_dquant=False, use_fp16=True, use_ipex=False, use_jit=False, use_tensorrt=True)
Benchmarking densenet -- Batch: 512; Input: 224
