batch_size: [1]
hidden_size: [16, 32, 64, 128, 256]
num_heads: [1, 2, 4, 8, 16]
seq_lens: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]
act_fn: "relu"
iters: 10
num_threads: 1
requires_grad: False
dropout: null
use_jit: False
use_cuda: False
device: "cpu"
device_idx: null
